{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gx5wldLi5oJ",
    "outputId": "d34eea43-63b3-4b08-d090-7903108a4970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyswarms in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (1.11.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (3.7.5)\n",
      "Requirement already satisfied: attrs in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (24.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (4.66.5)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (6.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=1.3.1->pyswarms) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->pyswarms) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-fuzzy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyswarms\n",
    "!pip install scikit-fuzzy\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a99aCVAF2TMh",
    "outputId": "2d6cf782-caa1-4c37-dbfa-dcba3b49b560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AD': 0, 'CI': 1, 'CN': 2}\n",
      "Batch size: torch.Size([32, 3, 224, 224]), Labels: tensor([2, 2, 2, 0, 1, 2, 1, 1, 2, 1, 1, 1, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        2, 2, 0, 1, 1, 0, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize images\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"dataset\"\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Check class mapping\n",
    "print(dataset.class_to_idx)  # {'1': 0, '2': 1, '3': 2, '4': 3}\n",
    "\n",
    "# Example: Load a batch\n",
    "for images, labels in dataloader:\n",
    "    print(f\"Batch size: {images.shape}, Labels: {labels}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxeFeMso1mv1",
    "outputId": "1941a00d-e042-475e-8d25-405f05d59894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preprocessing & Splitting Completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set paths\n",
    "dataset_path = \"dataset\"  # Root dataset path\n",
    "output_dir = \"Processed_adni_Dataset\"  # Output directory\n",
    "\n",
    "# Define train-test split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Target image size\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Class labels\n",
    "classes = [\"AD\", \"CI\", \"CN\"]\n",
    "\n",
    "# Create train & test directories\n",
    "for split in [\"train\", \"test\"]:\n",
    "    for folder in classes:\n",
    "        os.makedirs(os.path.join(output_dir, split, folder), exist_ok=True)\n",
    "\n",
    "# Function to preprocess and save images\n",
    "def process_and_split_images():\n",
    "    for split in [\"train\", \"test\"]:  # Process both train and test folders\n",
    "        for category in classes:  # Iterate through class folders\n",
    "            class_path = os.path.join(dataset_path, category)\n",
    "            if not os.path.exists(class_path):\n",
    "                print(f\"Warning: {class_path} not found. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            images = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            random.shuffle(images)  # Shuffle for randomness\n",
    "\n",
    "            split_index = int(len(images) * train_ratio)\n",
    "            train_images, test_images = images[:split_index], images[split_index:]\n",
    "\n",
    "            # Save images\n",
    "            for image_name in train_images:\n",
    "                process_and_save(image_name, class_path, os.path.join(output_dir, \"train\", category))\n",
    "\n",
    "            for image_name in test_images:\n",
    "                process_and_save(image_name, class_path, os.path.join(output_dir, \"test\", category))\n",
    "\n",
    "# Function to load, preprocess, and save images\n",
    "def process_and_save(image_name, src_folder, dest_folder):\n",
    "    src_path = os.path.join(src_folder, image_name)\n",
    "    dest_path = os.path.join(dest_folder, image_name)\n",
    "\n",
    "    try:\n",
    "        with Image.open(src_path) as img:\n",
    "            img = img.convert(\"RGB\")  # Convert to RGB (if grayscale)\n",
    "            img = img.resize(img_size)  # Resize image\n",
    "            img.save(dest_path)  # Save processed image\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {src_path}: {e}\")\n",
    "\n",
    "# Run preprocessing\n",
    "process_and_split_images()\n",
    "print(\"Dataset Preprocessing & Splitting Completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at Processed_adni_Dataset\\adni_dataset_info.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Define CSV file path\n",
    "csv_file = os.path.join(output_dir, \"adni_dataset_info.csv\")\n",
    "\n",
    "# Collect image data\n",
    "image_data = []\n",
    "labels = []\n",
    "for split in [\"train\", \"test\"]: \n",
    "     split_dir = os.path.join(\"dataset\", split)\n",
    "     split_dir = os.path.join(output_dir, split)\n",
    "     for category in [\"AD\", \"CI\", \"CN\"]:\n",
    "        category_dir = os.path.join(split_dir, category)\n",
    "        for image_name in os.listdir(category_dir):\n",
    "            image_path = os.path.join(category_dir, image_name)\n",
    "            image_data.append([image_path, image_name, category])\n",
    "            labels.append(category)\n",
    "\n",
    "# Write to CSV file\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Image_Path\", \"Image_Name\", \"Label\"])\n",
    "    writer.writerows(image_data)\n",
    "\n",
    "print(f\"CSV file saved at {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Processed_adni_Dataset/adni_dataset_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_BXXowo2FkD",
    "outputId": "e2dc9070-ee04-486a-f890-e4b80fcb7c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Image_Path            Image_Name  \\\n",
      "0  Processed_adni_Dataset\\train\\AD\\AD002_S_0816a0...  AD002_S_0816a076.png   \n",
      "1  Processed_adni_Dataset\\train\\AD\\AD002_S_0816a0...  AD002_S_0816a077.png   \n",
      "2  Processed_adni_Dataset\\train\\AD\\AD002_S_0816a0...  AD002_S_0816a078.png   \n",
      "3  Processed_adni_Dataset\\train\\AD\\AD002_S_0816a0...  AD002_S_0816a079.png   \n",
      "4  Processed_adni_Dataset\\train\\AD\\AD002_S_0816a0...  AD002_S_0816a080.png   \n",
      "\n",
      "  Label  \n",
      "0    AD  \n",
      "1    AD  \n",
      "2    AD  \n",
      "3    AD  \n",
      "4    AD  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6816 entries, 0 to 6815\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Image_Path  6816 non-null   object\n",
      " 1   Image_Name  6816 non-null   object\n",
      " 2   Label       6816 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 159.9+ KB\n",
      "None\n",
      "Label\n",
      "CI    3430\n",
      "CN    1906\n",
      "AD    1480\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check basic information\n",
    "print(df.info())\n",
    "\n",
    "# Check the label distribution\n",
    "print(df['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "QNxvTi302b3Q",
    "outputId": "af21cbf7-7150-45a0-94ea-20c5d34ce1dc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHNCAYAAAD/t2TXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA45ElEQVR4nO3de1RVdf7/8dcB4eDtQKjcFBEvqah4Tyk1TQIVKyddZTVeSm00sNS+6lDmhaacsfJWljPfMprSSXPKTPOCINkFb/TFC6mTjoqlB0yDg6aosH9/tDi/TqCpAQfdz8daey3O/rzP3u8PUbza57M3FsMwDAEAAJiYh7sbAAAAcDcCEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEYBrcuTIEVksFr388ssVdsz09HRZLBalp6dX2DFLzZw5UxaLpcKPW57evXurd+/eztel81q5cmWVnH/kyJFq0qRJlZwLuNkQiAATSE5OlsVi0c6dO93dyu9SOo/SzcfHRyEhIYqNjdXChQtVWFhYIec5fvy4Zs6cqaysrAo5XkWqzr0BNzICEYAbTlJSkt5991298cYbGj9+vCRpwoQJateunXbv3u1SO23aNJ07d+6ajn/8+HHNmjXrmkPHxo0btXHjxmt6z7W6Um//+7//qwMHDlTq+YGbVQ13NwAA16p///7q0qWL83ViYqLS0tI0cOBA3Xvvvdq3b59q1qwpSapRo4Zq1Kjc/9T99NNPqlWrlry9vSv1PL/Fy8vLrecHbmRcIQIgSbpw4YKmT5+uzp07y9fXV7Vr11bPnj21efPmy75n3rx5CgsLU82aNXXnnXdq7969ZWr279+vIUOGyN/fXz4+PurSpYtWr15d4f3fddddeu6553T06FG99957zv3lrSFKSUlRjx495Ofnpzp16qhly5Z65plnJP287qdr166SpEcffdT58VxycrKkn9cJtW3bVpmZmerVq5dq1arlfO+v1xCVKi4u1jPPPKOgoCDVrl1b9957r44dO+ZS06RJE40cObLMe395zN/qrbw1RGfPntXTTz+t0NBQWa1WtWzZUi+//LIMw3Cps1gsSkhI0KpVq9S2bVtZrVa1adNG69evL/8bDtxkuEIEQJLkcDj05ptv6qGHHtKYMWNUWFiot956S7Gxsdq+fbs6dOjgUv/Pf/5ThYWFio+P1/nz57VgwQLddddd2rNnjwIDAyVJ2dnZuuOOO9SwYUP9+c9/Vu3atbVixQoNGjRI//73v/WHP/yhQucwbNgwPfPMM9q4caPGjBlTbk12drYGDhyoyMhIJSUlyWq16uDBg/ryyy8lSa1bt1ZSUpKmT5+uxx9/XD179pQk3X777c5jnDp1Sv3799fQoUP1xz/+0Tnfy3nhhRdksVg0depU5eXlaf78+YqOjlZWVpbzStbVuJrefskwDN17773avHmzRo0apQ4dOmjDhg2aPHmyvv/+e82bN8+l/osvvtCHH36oJ554QnXr1tXChQs1ePBg5eTkqF69elfdJ3BDMgDc9N5++21DkrFjx47L1ly6dMkoKipy2ffjjz8agYGBxmOPPebcd/jwYUOSUbNmTeO7775z7t+2bZshyZg4caJzX9++fY127doZ58+fd+4rKSkxbr/9dqNFixbOfZs3bzYkGZs3b/7d8/D19TU6duzofD1jxgzjl/+pmzdvniHJOHny5GWPsWPHDkOS8fbbb5cZu/POOw1JxuLFi8sdu/POO8vMq2HDhobD4XDuX7FihSHJWLBggXNfWFiYMWLEiN885pV6GzFihBEWFuZ8vWrVKkOS8Ze//MWlbsiQIYbFYjEOHjzo3CfJ8Pb2dtm3a9cuQ5Lx6quvljkXcLPhIzMAkiRPT0/nGpiSkhKdPn1aly5dUpcuXfT111+XqR80aJAaNmzofH3bbbepW7du+vTTTyVJp0+fVlpamh544AEVFhbqhx9+0A8//KBTp04pNjZW3377rb7//vsKn0edOnWueLeZn5+fJOnjjz9WSUnJdZ3DarXq0Ucfver64cOHq27dus7XQ4YMUXBwsPN7VVk+/fRTeXp66sknn3TZ//TTT8swDK1bt85lf3R0tJo1a+Z8HRkZKZvNpv/+97+V2idQHRCIADi98847ioyMlI+Pj+rVq6cGDRpo7dq1KigoKFPbokWLMvtuvfVWHTlyRJJ08OBBGYah5557Tg0aNHDZZsyYIUnKy8ur8DmcOXPGJXz82oMPPqg77rhDo0ePVmBgoIYOHaoVK1ZcUzhq2LDhNS2g/vX3ymKxqHnz5s7vVWU5evSoQkJCynw/Wrdu7Rz/pcaNG5c5xi233KIff/yx8poEqgnWEAGQJL333nsaOXKkBg0apMmTJysgIECenp6aPXu2Dh06dM3HKw0Y//M//6PY2Nhya5o3b/67ev617777TgUFBVc8bs2aNbVlyxZt3rxZa9eu1fr167V8+XLddddd2rhxozw9PX/zPNey7udqXe7hkcXFxVfVU0W43HmMXy3ABm5GBCIAkqSVK1eqadOm+vDDD11+OZdezfm1b7/9tsy+//znP867nJo2bSrp51vBo6OjK77hcrz77ruSdNkAVsrDw0N9+/ZV3759NXfuXL344ot69tlntXnzZkVHR1f4k61//b0yDEMHDx5UZGSkc98tt9yi/Pz8Mu89evSo83spXT44lScsLEybNm1SYWGhy1Wi/fv3O8cB/IyPzABI+v9XB355NWDbtm3KyMgot37VqlUua4C2b9+ubdu2qX///pKkgIAA9e7dW3//+9914sSJMu8/efJkRbavtLQ0Pf/88woPD9cjjzxy2brTp0+X2Vd6B11RUZEkqXbt2pJUbkC5HqV35JVauXKlTpw44fxeSVKzZs20detWXbhwwblvzZo1ZW7Pv5beBgwYoOLiYr322msu++fNmyeLxeJyfsDsuEIEmMiSJUvKfa7MU089pYEDB+rDDz/UH/7wB8XFxenw4cNavHixIiIidObMmTLvad68uXr06KFx48apqKhI8+fPV7169TRlyhRnzaJFi9SjRw+1a9dOY8aMUdOmTZWbm6uMjAx999132rVr13XNY926ddq/f78uXbqk3NxcpaWlKSUlRWFhYVq9erV8fHwu+96kpCRt2bJFcXFxCgsLU15enl5//XU1atRIPXr0kPRzOPHz89PixYtVt25d1a5dW926dVN4ePh19evv768ePXro0UcfVW5urubPn6/mzZu7PBpg9OjRWrlypfr166cHHnhAhw4d0nvvveeyyPlae7vnnnvUp08fPfvsszpy5Ijat2+vjRs36uOPP9aECRPKHBswNbfe4wagSpTern657dixY0ZJSYnx4osvGmFhYYbVajU6duxorFmzpsyt3KW33b/00kvGK6+8YoSGhhpWq9Xo2bOnsWvXrjLnPnTokDF8+HAjKCjI8PLyMho2bGgMHDjQWLlypbPmWm+7L928vb2NoKAg4+677zYWLFjgcmt7qV/fdp+ammrcd999RkhIiOHt7W2EhIQYDz30kPGf//zH5X0ff/yxERERYdSoUcPlNvc777zTaNOmTbn9Xe62+3/9619GYmKiERAQYNSsWdOIi4szjh49Wub9r7zyitGwYUPDarUad9xxh7Fz584yx7xSb7/+Z2UYhlFYWGhMnDjRCAkJMby8vIwWLVoYL730klFSUuJSJ8mIj48v09PlHgcA3GwshsFqOQAAYG6sIQIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKZHIAIAAKbHgxmvQklJiY4fP666detW+CP9AQBA5TAMQ4WFhQoJCZGHx5WvARGIrsLx48cVGhrq7jYAAMB1OHbsmBo1anTFGgLRVSj9o4jHjh2TzWZzczcAAOBqOBwOhYaGuvxx48shEF2F0o/JbDYbgQgAgBvM1Sx3YVE1AAAwPQIRAAAwPQIRAAAwPbcGojfeeEORkZHOtTlRUVFat26dc7x3796yWCwu29ixY12OkZOTo7i4ONWqVUsBAQGaPHmyLl265FKTnp6uTp06yWq1qnnz5kpOTq6K6QEAgBuEWxdVN2rUSH/961/VokULGYahd955R/fdd5/+7//+T23atJEkjRkzRklJSc731KpVy/l1cXGx4uLiFBQUpK+++konTpzQ8OHD5eXlpRdffFGSdPjwYcXFxWns2LFaunSpUlNTNXr0aAUHBys2NrZqJwwAAKoli2EYhrub+CV/f3+99NJLGjVqlHr37q0OHTpo/vz55dauW7dOAwcO1PHjxxUYGChJWrx4saZOnaqTJ0/K29tbU6dO1dq1a7V3717n+4YOHar8/HytX7/+qnpyOBzy9fVVQUEBd5kBAHCDuJbf39VmDVFxcbHef/99nT17VlFRUc79S5cuVf369dW2bVslJibqp59+co5lZGSoXbt2zjAkSbGxsXI4HMrOznbWREdHu5wrNjZWGRkZl+2lqKhIDofDZQMAADcvtz+HaM+ePYqKitL58+dVp04dffTRR4qIiJAkPfzwwwoLC1NISIh2796tqVOn6sCBA/rwww8lSXa73SUMSXK+ttvtV6xxOBw6d+6catasWaan2bNna9asWRU+VwAAUD25PRC1bNlSWVlZKigo0MqVKzVixAh99tlnioiI0OOPP+6sa9eunYKDg9W3b18dOnRIzZo1q7SeEhMTNWnSJOfr0iddAgCAm5PbPzLz9vZW8+bN1blzZ82ePVvt27fXggULyq3t1q2bJOngwYOSpKCgIOXm5rrUlL4OCgq6Yo3NZiv36pAkWa1W551vPJ0aAICbn9sD0a+VlJSoqKio3LGsrCxJUnBwsCQpKipKe/bsUV5enrMmJSVFNpvN+bFbVFSUUlNTXY6TkpLisk4JAACYm1s/MktMTFT//v3VuHFjFRYWatmyZUpPT9eGDRt06NAhLVu2TAMGDFC9evW0e/duTZw4Ub169VJkZKQkKSYmRhERERo2bJjmzJkju92uadOmKT4+XlarVZI0duxYvfbaa5oyZYoee+wxpaWlacWKFVq7dq07pw4AAKoRtwaivLw8DR8+XCdOnJCvr68iIyO1YcMG3X333Tp27Jg2bdqk+fPn6+zZswoNDdXgwYM1bdo05/s9PT21Zs0ajRs3TlFRUapdu7ZGjBjh8tyi8PBwrV27VhMnTtSCBQvUqFEjvfnmmzyDCAAAOFW75xBVRzyHCACAG8+1/P52+11mqFhN/sxHgRXhyF/j3N0CAKAKVbtF1QAAAFWNQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEzPrYHojTfeUGRkpGw2m2w2m6KiorRu3Trn+Pnz5xUfH6969eqpTp06Gjx4sHJzc12OkZOTo7i4ONWqVUsBAQGaPHmyLl265FKTnp6uTp06yWq1qnnz5kpOTq6K6QEAgBuEWwNRo0aN9Ne//lWZmZnauXOn7rrrLt13333Kzs6WJE2cOFGffPKJPvjgA3322Wc6fvy47r//fuf7i4uLFRcXpwsXLuirr77SO++8o+TkZE2fPt1Zc/jwYcXFxalPnz7KysrShAkTNHr0aG3YsKHK5wsAAKoni2EYhrub+CV/f3+99NJLGjJkiBo0aKBly5ZpyJAhkqT9+/erdevWysjIUPfu3bVu3ToNHDhQx48fV2BgoCRp8eLFmjp1qk6ePClvb29NnTpVa9eu1d69e53nGDp0qPLz87V+/fqr6snhcMjX11cFBQWy2WwVP+kK1OTPa93dwk3hyF/j3N0CAOB3upbf39VmDVFxcbHef/99nT17VlFRUcrMzNTFixcVHR3trGnVqpUaN26sjIwMSVJGRobatWvnDEOSFBsbK4fD4bzKlJGR4XKM0prSY5SnqKhIDofDZQMAADcvtweiPXv2qE6dOrJarRo7dqw++ugjRUREyG63y9vbW35+fi71gYGBstvtkiS73e4ShkrHS8euVONwOHTu3Llye5o9e7Z8fX2dW2hoaEVMFQAAVFNuD0QtW7ZUVlaWtm3bpnHjxmnEiBH65ptv3NpTYmKiCgoKnNuxY8fc2g8AAKhcNdzdgLe3t5o3by5J6ty5s3bs2KEFCxbowQcf1IULF5Sfn+9ylSg3N1dBQUGSpKCgIG3fvt3leKV3of2y5td3puXm5spms6lmzZrl9mS1WmW1WitkfgAAoPpz+xWiXyspKVFRUZE6d+4sLy8vpaamOscOHDignJwcRUVFSZKioqK0Z88e5eXlOWtSUlJks9kUERHhrPnlMUprSo8BAADg1itEiYmJ6t+/vxo3bqzCwkItW7ZM6enp2rBhg3x9fTVq1ChNmjRJ/v7+stlsGj9+vKKiotS9e3dJUkxMjCIiIjRs2DDNmTNHdrtd06ZNU3x8vPMKz9ixY/Xaa69pypQpeuyxx5SWlqYVK1Zo7VruxgIAAD9zayDKy8vT8OHDdeLECfn6+ioyMlIbNmzQ3XffLUmaN2+ePDw8NHjwYBUVFSk2Nlavv/668/2enp5as2aNxo0bp6ioKNWuXVsjRoxQUlKSsyY8PFxr167VxIkTtWDBAjVq1EhvvvmmYmNjq3y+AACgeqp2zyGqjngOkfnwHCIAuPHdkM8hAgAAcBcCEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD23BqLZs2era9euqlu3rgICAjRo0CAdOHDApaZ3796yWCwu29ixY11qcnJyFBcXp1q1aikgIECTJ0/WpUuXXGrS09PVqVMnWa1WNW/eXMnJyZU9PQAAcINwayD67LPPFB8fr61btyolJUUXL15UTEyMzp4961I3ZswYnThxwrnNmTPHOVZcXKy4uDhduHBBX331ld555x0lJydr+vTpzprDhw8rLi5Offr0UVZWliZMmKDRo0drw4YNVTZXAABQfdVw58nXr1/v8jo5OVkBAQHKzMxUr169nPtr1aqloKCgco+xceNGffPNN9q0aZMCAwPVoUMHPf/885o6dapmzpwpb29vLV68WOHh4XrllVckSa1bt9YXX3yhefPmKTY2tvImCAAAbgjVag1RQUGBJMnf399l/9KlS1W/fn21bdtWiYmJ+umnn5xjGRkZateunQIDA537YmNj5XA4lJ2d7ayJjo52OWZsbKwyMjLK7aOoqEgOh8NlAwAANy+3XiH6pZKSEk2YMEF33HGH2rZt69z/8MMPKywsTCEhIdq9e7emTp2qAwcO6MMPP5Qk2e12lzAkyfnabrdfscbhcOjcuXOqWbOmy9js2bM1a9asCp8jAAConqpNIIqPj9fevXv1xRdfuOx//PHHnV+3a9dOwcHB6tu3rw4dOqRmzZpVSi+JiYmaNGmS87XD4VBoaGilnAsAALhftfjILCEhQWvWrNHmzZvVqFGjK9Z269ZNknTw4EFJUlBQkHJzc11qSl+Xrju6XI3NZitzdUiSrFarbDabywYAAG5ebg1EhmEoISFBH330kdLS0hQeHv6b78nKypIkBQcHS5KioqK0Z88e5eXlOWtSUlJks9kUERHhrElNTXU5TkpKiqKioipoJgAA4Ebm1kAUHx+v9957T8uWLVPdunVlt9tlt9t17tw5SdKhQ4f0/PPPKzMzU0eOHNHq1as1fPhw9erVS5GRkZKkmJgYRUREaNiwYdq1a5c2bNigadOmKT4+XlarVZI0duxY/fe//9WUKVO0f/9+vf7661qxYoUmTpzotrkDAIDqw62B6I033lBBQYF69+6t4OBg57Z8+XJJkre3tzZt2qSYmBi1atVKTz/9tAYPHqxPPvnEeQxPT0+tWbNGnp6eioqK0h//+EcNHz5cSUlJzprw8HCtXbtWKSkpat++vV555RW9+eab3HIPAAAkSRbDMAx3N1HdORwO+fr6qqCgoNqvJ2ry57XubuGmcOSvce5uAQDwO13L7+9qsagaAADAnQhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9NwaiGbPnq2uXbuqbt26CggI0KBBg3TgwAGXmvPnzys+Pl716tVTnTp1NHjwYOXm5rrU5OTkKC4uTrVq1VJAQIAmT56sS5cuudSkp6erU6dOslqtat68uZKTkyt7egAA4Abh1kD02WefKT4+Xlu3blVKSoouXryomJgYnT171lkzceJEffLJJ/rggw/02Wef6fjx47r//vud48XFxYqLi9OFCxf01Vdf6Z133lFycrKmT5/urDl8+LDi4uLUp08fZWVlacKECRo9erQ2bNhQpfMFAADVk8UwDMPdTZQ6efKkAgIC9Nlnn6lXr14qKChQgwYNtGzZMg0ZMkSStH//frVu3VoZGRnq3r271q1bp4EDB+r48eMKDAyUJC1evFhTp07VyZMn5e3tralTp2rt2rXau3ev81xDhw5Vfn6+1q9f/5t9ORwO+fr6qqCgQDabrXImX0Ga/Hmtu1u4KRz5a5y7WwAA/E7X8vu7Wq0hKigokCT5+/tLkjIzM3Xx4kVFR0c7a1q1aqXGjRsrIyNDkpSRkaF27do5w5AkxcbGyuFwKDs721nzy2OU1pQe49eKiorkcDhcNgAAcPOqNoGopKREEyZM0B133KG2bdtKkux2u7y9veXn5+dSGxgYKLvd7qz5ZRgqHS8du1KNw+HQuXPnyvQye/Zs+fr6OrfQ0NAKmSMAAKieqk0gio+P1969e/X++++7uxUlJiaqoKDAuR07dszdLQEAgEpUw90NSFJCQoLWrFmjLVu2qFGjRs79QUFBunDhgvLz812uEuXm5iooKMhZs337dpfjld6F9suaX9+ZlpubK5vNppo1a5bpx2q1ymq1VsjcAABA9XddV4iaNm2qU6dOldmfn5+vpk2bXvVxDMNQQkKCPvroI6WlpSk8PNxlvHPnzvLy8lJqaqpz34EDB5STk6OoqChJUlRUlPbs2aO8vDxnTUpKimw2myIiIpw1vzxGaU3pMQAAgLld1xWiI0eOqLi4uMz+oqIiff/991d9nPj4eC1btkwff/yx6tat61zz4+vrq5o1a8rX11ejRo3SpEmT5O/vL5vNpvHjxysqKkrdu3eXJMXExCgiIkLDhg3TnDlzZLfbNW3aNMXHxzuv8owdO1avvfaapkyZoscee0xpaWlasWKF1q7ljiwAAHCNgWj16tXOrzds2CBfX1/n6+LiYqWmpqpJkyZXfbw33nhDktS7d2+X/W+//bZGjhwpSZo3b548PDw0ePBgFRUVKTY2Vq+//rqz1tPTU2vWrNG4ceMUFRWl2rVra8SIEUpKSnLWhIeHa+3atZo4caIWLFigRo0a6c0331RsbOw1zB4AANysruk5RB4eP3/CZrFY9Ou3eXl5qUmTJnrllVc0cODAiu3SzXgOkfnwHCIAuPFdy+/va7pCVFJSIunnKy47duxQ/fr1r79LAACAauK61hAdPny4ovsAAABwm+u+7T41NVWpqanKy8tzXjkqtWTJkt/dGAAAQFW5rkA0a9YsJSUlqUuXLgoODpbFYqnovgDcJFjXVnFY2wZUnusKRIsXL1ZycrKGDRtW0f0AAABUuet6MOOFCxd0++23V3QvAAAAbnFdgWj06NFatmxZRfcCAADgFtf1kdn58+f1j3/8Q5s2bVJkZKS8vLxcxufOnVshzQEAAFSF6wpEu3fvVocOHSRJe/fudRljgTUAALjRXFcg2rx5c0X3AQAA4DbXtYYIAADgZnJdV4j69OlzxY/G0tLSrrshAACAqnZdgah0/VCpixcvKisrS3v37tWIESMqoi8AAIAqc12BaN68eeXunzlzps6cOfO7GgIAAKhqFbqG6I9//CN/xwwAANxwKjQQZWRkyMfHpyIPCQAAUOmu6yOz+++/3+W1YRg6ceKEdu7cqeeee65CGgMAAKgq1xWIfH19XV57eHioZcuWSkpKUkxMTIU0BgAAUFWuKxC9/fbbFd0HAACA21xXICqVmZmpffv2SZLatGmjjh07VkhTAAAAVem6AlFeXp6GDh2q9PR0+fn5SZLy8/PVp08fvf/++2rQoEFF9ggAAFCprusus/Hjx6uwsFDZ2dk6ffq0Tp8+rb1798rhcOjJJ5+s6B4BAAAq1XVdIVq/fr02bdqk1q1bO/dFRERo0aJFLKoGAAA3nOu6QlRSUiIvL68y+728vFRSUvK7mwIAAKhK1xWI7rrrLj311FM6fvy4c9/333+viRMnqm/fvhXWHAAAQFW4rkD02muvyeFwqEmTJmrWrJmaNWum8PBwORwOvfrqqxXdIwAAQKW6rjVEoaGh+vrrr7Vp0ybt379fktS6dWtFR0dXaHMAAABV4ZquEKWlpSkiIkIOh0MWi0V33323xo8fr/Hjx6tr165q06aNPv/888rqFQAAoFJcUyCaP3++xowZI5vNVmbM19dXf/rTnzR37twKaw4AAKAqXFMg2rVrl/r163fZ8ZiYGGVmZv7upgAAAKrSNQWi3Nzccm+3L1WjRg2dPHnydzcFAABQla4pEDVs2FB79+697Pju3bsVHBz8u5sCAACoStcUiAYMGKDnnntO58+fLzN27tw5zZgxQwMHDqyw5gAAAKrCNd12P23aNH344Ye69dZblZCQoJYtW0qS9u/fr0WLFqm4uFjPPvtspTQKAABQWa4pEAUGBuqrr77SuHHjlJiYKMMwJEkWi0WxsbFatGiRAgMDK6VRAACAynLND2YMCwvTp59+qh9//FEHDx6UYRhq0aKFbrnllsroDwAAoNJd15OqJemWW25R165dK7IXAAAAt7iuv2UGAABwMyEQAQAA0yMQAQAA03NrINqyZYvuuecehYSEyGKxaNWqVS7jI0eOlMVicdl+/adDTp8+rUceeUQ2m01+fn4aNWqUzpw541Kze/du9ezZUz4+PgoNDdWcOXMqe2oAAOAG4tZAdPbsWbVv316LFi26bE2/fv104sQJ5/avf/3LZfyRRx5Rdna2UlJStGbNGm3ZskWPP/64c9zhcCgmJkZhYWHKzMzUSy+9pJkzZ+of//hHpc0LAADcWK77LrOK0L9/f/Xv3/+KNVarVUFBQeWO7du3T+vXr9eOHTvUpUsXSdKrr76qAQMG6OWXX1ZISIiWLl2qCxcuaMmSJfL29labNm2UlZWluXPnugQnAABgXtV+DVF6eroCAgLUsmVLjRs3TqdOnXKOZWRkyM/PzxmGJCk6OloeHh7atm2bs6ZXr17y9vZ21sTGxurAgQP68ccfq24iAACg2nLrFaLf0q9fP91///0KDw/XoUOH9Mwzz6h///7KyMiQp6en7Ha7AgICXN5To0YN+fv7y263S5LsdrvCw8Ndakqfpm2328t9oGRRUZGKioqcrx0OR0VPDQAAVCPVOhANHTrU+XW7du0UGRmpZs2aKT09XX379q20886ePVuzZs2qtOMDAIDqpdp/ZPZLTZs2Vf369XXw4EFJUlBQkPLy8lxqLl26pNOnTzvXHQUFBSk3N9elpvT15dYmJSYmqqCgwLkdO3asoqcCAACqkWp9hejXvvvuO506dUrBwcGSpKioKOXn5yszM1OdO3eWJKWlpamkpETdunVz1jz77LO6ePGivLy8JEkpKSlq2bLlZf/+mtVqldVqrYIZAQCqWpM/r3V3CzeNI3+Nc3cLFcatV4jOnDmjrKwsZWVlSZIOHz6srKws5eTk6MyZM5o8ebK2bt2qI0eOKDU1Vffdd5+aN2+u2NhYSVLr1q3Vr18/jRkzRtu3b9eXX36phIQEDR06VCEhIZKkhx9+WN7e3ho1apSys7O1fPlyLViwQJMmTXLXtAEAQDXj1kC0c+dOdezYUR07dpQkTZo0SR07dtT06dPl6emp3bt3695779Wtt96qUaNGqXPnzvr8889drt4sXbpUrVq1Ut++fTVgwAD16NHD5RlDvr6+2rhxow4fPqzOnTvr6aef1vTp07nlHgAAOLn1I7PevXvLMIzLjm/YsOE3j+Hv769ly5ZdsSYyMlKff/75NfcHAADM4YZaVA0AAFAZCEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD0CEQAAMD03BqItmzZonvuuUchISGyWCxatWqVy7hhGJo+fbqCg4NVs2ZNRUdH69tvv3WpOX36tB555BHZbDb5+flp1KhROnPmjEvN7t271bNnT/n4+Cg0NFRz5syp7KkBAIAbiFsD0dmzZ9W+fXstWrSo3PE5c+Zo4cKFWrx4sbZt26batWsrNjZW58+fd9Y88sgjys7OVkpKitasWaMtW7bo8ccfd447HA7FxMQoLCxMmZmZeumllzRz5kz94x//qPT5AQCAG0MNd568f//+6t+/f7ljhmFo/vz5mjZtmu677z5J0j//+U8FBgZq1apVGjp0qPbt26f169drx44d6tKliyTp1Vdf1YABA/Tyyy8rJCRES5cu1YULF7RkyRJ5e3urTZs2ysrK0ty5c12CEwAAMK9qu4bo8OHDstvtio6Odu7z9fVVt27dlJGRIUnKyMiQn5+fMwxJUnR0tDw8PLRt2zZnTa9eveTt7e2siY2N1YEDB/Tjjz+We+6ioiI5HA6XDQAA3LyqbSCy2+2SpMDAQJf9gYGBzjG73a6AgACX8Ro1asjf39+lprxj/PIcvzZ79mz5+vo6t9DQ0N8/IQAAUG1V20DkTomJiSooKHBux44dc3dLAACgElXbQBQUFCRJys3Nddmfm5vrHAsKClJeXp7L+KVLl3T69GmXmvKO8ctz/JrVapXNZnPZAADAzavaBqLw8HAFBQUpNTXVuc/hcGjbtm2KioqSJEVFRSk/P1+ZmZnOmrS0NJWUlKhbt27Omi1btujixYvOmpSUFLVs2VK33HJLFc0GAABUZ24NRGfOnFFWVpaysrIk/byQOisrSzk5ObJYLJowYYL+8pe/aPXq1dqzZ4+GDx+ukJAQDRo0SJLUunVr9evXT2PGjNH27dv15ZdfKiEhQUOHDlVISIgk6eGHH5a3t7dGjRql7OxsLV++XAsWLNCkSZPcNGsAAFDduPW2+507d6pPnz7O16UhZcSIEUpOTtaUKVN09uxZPf7448rPz1ePHj20fv16+fj4ON+zdOlSJSQkqG/fvvLw8NDgwYO1cOFC57ivr682btyo+Ph4de7cWfXr19f06dO55R4AADi5NRD17t1bhmFcdtxisSgpKUlJSUmXrfH399eyZcuueJ7IyEh9/vnn190nAAC4uVXbNUQAAABVhUAEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMj0AEAABMr1oHopkzZ8pisbhsrVq1co6fP39e8fHxqlevnurUqaPBgwcrNzfX5Rg5OTmKi4tTrVq1FBAQoMmTJ+vSpUtVPRUAAFCN1XB3A7+lTZs22rRpk/N1jRr/v+WJEydq7dq1+uCDD+Tr66uEhATdf//9+vLLLyVJxcXFiouLU1BQkL766iudOHFCw4cPl5eXl1588cUqnwsAAKieqn0gqlGjhoKCgsrsLygo0FtvvaVly5bprrvukiS9/fbbat26tbZu3aru3btr48aN+uabb7Rp0yYFBgaqQ4cOev755zV16lTNnDlT3t7eVT0dAABQDVXrj8wk6dtvv1VISIiaNm2qRx55RDk5OZKkzMxMXbx4UdHR0c7aVq1aqXHjxsrIyJAkZWRkqF27dgoMDHTWxMbGyuFwKDs7+7LnLCoqksPhcNkAAMDNq1oHom7duik5OVnr16/XG2+8ocOHD6tnz54qLCyU3W6Xt7e3/Pz8XN4TGBgou90uSbLb7S5hqHS8dOxyZs+eLV9fX+cWGhpasRMDAADVSrX+yKx///7OryMjI9WtWzeFhYVpxYoVqlmzZqWdNzExUZMmTXK+djgchCIAAG5i1foK0a/5+fnp1ltv1cGDBxUUFKQLFy4oPz/fpSY3N9e55igoKKjMXWelr8tbl1TKarXKZrO5bAAA4OZ1QwWiM2fO6NChQwoODlbnzp3l5eWl1NRU5/iBAweUk5OjqKgoSVJUVJT27NmjvLw8Z01KSopsNpsiIiKqvH8AAFA9VeuPzP7nf/5H99xzj8LCwnT8+HHNmDFDnp6eeuihh+Tr66tRo0Zp0qRJ8vf3l81m0/jx4xUVFaXu3btLkmJiYhQREaFhw4Zpzpw5stvtmjZtmuLj42W1Wt08OwAAUF1U60D03Xff6aGHHtKpU6fUoEED9ejRQ1u3blWDBg0kSfPmzZOHh4cGDx6soqIixcbG6vXXX3e+39PTU2vWrNG4ceMUFRWl2rVra8SIEUpKSnLXlAAAQDVUrQPR+++/f8VxHx8fLVq0SIsWLbpsTVhYmD799NOKbg0AANxEbqg1RAAAAJWBQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEyPQAQAAEzPVIFo0aJFatKkiXx8fNStWzdt377d3S0BAIBqwDSBaPny5Zo0aZJmzJihr7/+Wu3bt1dsbKzy8vLc3RoAAHAz0wSiuXPnasyYMXr00UcVERGhxYsXq1atWlqyZIm7WwMAAG5Ww90NVIULFy4oMzNTiYmJzn0eHh6Kjo5WRkZGmfqioiIVFRU5XxcUFEiSHA5H5Tf7O5UU/eTuFm4KN8I/6xsFP5MVh5/LisHPZMWp7j+Tpf0ZhvGbtaYIRD/88IOKi4sVGBjosj8wMFD79+8vUz979mzNmjWrzP7Q0NBK6xHVi+98d3cAlMXPJaqbG+VnsrCwUL6+vlesMUUgulaJiYmaNGmS83VJSYlOnz6tevXqyWKxuLGzG5/D4VBoaKiOHTsmm83m7nYAfiZRLfFzWTEMw1BhYaFCQkJ+s9YUgah+/fry9PRUbm6uy/7c3FwFBQWVqbdarbJarS77/Pz8KrNF07HZbPxLjmqFn0lUR/xc/n6/dWWolCkWVXt7e6tz585KTU117ispKVFqaqqioqLc2BkAAKgOTHGFSJImTZqkESNGqEuXLrrttts0f/58nT17Vo8++qi7WwMAAG5mmkD04IMP6uTJk5o+fbrsdrs6dOig9evXl1lojcpltVo1Y8aMMh9JAu7CzySqI34uq57FuJp70QAAAG5iplhDBAAAcCUEIgAAYHoEIgAAYHoEIgAAYHoEIgAAYHoEIgAAYHqmeQ4Rqt7ChQuvqu7JJ5+s5E4AoHozDEOZmZk6cuSILBaLwsPD1bFjR/5+ZhXiOUSoNOHh4b9ZY7FY9N///rcKugGkPn36/OYvGIvF4vJnfoDKtnnzZo0aNUpHjx5V6a/k0lC0ZMkS9erVy80dmgOBCIBpTJw48bJjhYWFWrZsmYqKilRcXFyFXcHMDh48qPbt26tbt2566qmn1KpVKxmGoW+++UYLFy7Uzp07tXv3bjVt2tTdrd70CESoNGlpaUpISNDWrVvL/LXmgoIC3X777Vq8eLF69uzppg4B6dKlS1q0aJFeeOEF+fr66vnnn9fQoUPd3RZMIiEhQfv27Sv3qqRhGIqOjlZERIReffVVN3RnLiyqRqWZP3++xowZUyYMSZKvr6/+9Kc/ae7cuW7oDPjZ0qVL1bJlS/3tb3/TzJkztW/fPsIQqlR6eromTJhQ7pjFYtGECRO0efPmqm3KpAhEqDS7du1Sv379LjseExOjzMzMKuwI+Nn69evVoUMHPfHEExo5cqS+/fZbPfHEE6pRg/tMULVycnLUrl27y463bdtWR48ercKOzIt/+1FpcnNz5eXlddnxGjVq6OTJk1XYEcxu+/btmjp1qrZu3aqxY8dq06ZNql+/vrvbgomdOXNGtWrVuux4rVq19NNPP1VhR+ZFIEKladiwofbu3avmzZuXO757924FBwdXcVcws+7du6tmzZoaO3aswsPDtWzZsnLreBQEqtI333wju91e7tgPP/xQxd2YF4uqUWnGjx+v9PR07dixQz4+Pi5j586d02233aY+ffpc9fOKgN+rSZMmV3XbPY+CQFXx8PCQxWLRlX4VWywW7nysAgQiVJrc3Fx16tRJnp6eSkhIUMuWLSVJ+/fv16JFi1RcXKyvv/5agYGBbu4UANzjatYHFRYWqm3btlXQjbkRiFCpjh49qnHjxmnDhg0uDxyLjY3VokWLrurhjUBF4VEQuFEUFhbqX//6l9566y3t3LmTK0RVgECEKvHjjz/q4MGDMgxDLVq00C233OLulmBC9957r/r06XPZBzQuXLhQmzdv1kcffVTFnQE/27Jli9566y39+9//VkhIiO6//34NHjxYXbt2dXdrNz0CEQDTCAsL0/r169W6detyx/fv36+YmBjl5ORUcWcwM7vdruTkZL311ltyOBx64IEHtHjxYu3atUsRERHubs80eA4RANPgURCobu655x61bNlSu3fv1vz583X8+HGeSu0m3HYPwDR4FASqm3Xr1unJJ5/UuHHj1KJFC3e3Y2pcIQJgGgMGDNBzzz2n8+fPlxk7d+6cZsyYoYEDB7qhM5jVF198ocLCQnXu3FndunXTa6+9xrOH3IQ1RABMg0dBoLo6e/asli9friVLlmj79u0qLi7W3Llz9dhjj6lu3brubs8UCEQATIVHQaC6O3DggN566y29++67ys/P1913363Vq1e7u62bHoEIgCnxKAhUd8XFxfrkk0+0ZMkSAlEVIBABAADTY1E1AAAwPQIRAAAwPQIRAAAwPQIRANNITk6Wn5/f7z6OxWLRqlWrfvdxAFQfBCIAN5SRI0dq0KBB7m4DwE2GQAQAAEyPQATgpjF37ly1a9dOtWvXVmhoqJ544gmdOXOmTN2qVavUokUL+fj4KDY2VseOHXMZ//jjj9WpUyf5+PioadOmmjVrli5dulTuOS9cuKCEhAQFBwfLx8dHYWFhmj17dqXMD0DlIRABuGl4eHho4cKFys7O1jvvvKO0tDRNmTLFpeann37SCy+8oH/+85/68ssvlZ+fr6FDhzrHP//8cw0fPlxPPfWUvvnmG/39739XcnKyXnjhhXLPuXDhQq1evVorVqzQgQMHtHTpUjVp0qQypwmgEvBgRgA3lJEjRyo/P/+qFjWvXLlSY8eOdf6xzOTkZD366KPaunWrunXrJunnv2PWunVrbdu2Tbfddpuio6PVt29fJSYmOo/z3nvvacqUKTp+/LiknxdVf/TRRxo0aJCefPJJZWdna9OmTbJYLBU/YQBVgitEAG4amzZtUt++fdWwYUPVrVtXw4YN06lTp/TTTz85a2rUqKGuXbs6X7dq1Up+fn7at2+fJGnXrl1KSkpSnTp1nNuYMWN04sQJl+OUGjlypLKystSyZUs9+eST2rhxY+VPFECFIxABuCkcOXJEAwcOVGRkpP79738rMzNTixYtkvTzOp+rdebMGc2aNUtZWVnObc+ePfr222/l4+NTpr5Tp046fPiwnn/+eZ07d04PPPCAhgwZUmHzAlA1ari7AQCoCJmZmSopKdErr7wiD4+f/19vxYoVZeouXbqknTt36rbbbpP0818Wz8/PV+vWrSX9HHAOHDig5s2bX/W5bTabHnzwQT344IMaMmSI+vXrp9OnT8vf378CZgagKhCIANxwCgoKlJWV5bKvfv36unjxol599VXdc889+vLLL7V48eIy7/Xy8tL48eO1cOFC1ahRQwkJCerevbszIE2fPl0DBw5U48aNNWTIEHl4eGjXrl3au3ev/vKXv5Q53ty5cxUcHKyOHTvKw8NDH3zwgYKCgirkAZAAqg4fmQG44aSnp6tjx44u27vvvqu5c+fqb3/7m9q2baulS5eWe/t7rVq1NHXqVD388MO64447VKdOHS1fvtw5HhsbqzVr1mjjxo3q2rWrunfvrnnz5iksLKzcXurWras5c+aoS5cu6tq1q44cOaJPP/3UeZUKwI2Bu8wAAIDp8b8wAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9AhEAADA9P4fz8t0Vl3oXGoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot label distribution\n",
    "df['Label'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.xlabel(\"Labels\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhvkYN0m6R5S",
    "outputId": "5ca06df8-651b-4d2d-a7f0-84b8c2da581c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {'AD': 1.5351351351351352, 'CI': 0.6623906705539359, 'CN': 1.1920251836306401}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Calculate class weights\n",
    "label_counts = Counter(labels)\n",
    "total_samples = sum(label_counts.values())\n",
    "class_weights = {label: total_samples / (len(label_counts) * count) for label, count in label_counts.items()}\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUj2-NHi6nJD"
   },
   "source": [
    "Summary of Steps\n",
    "Use descriptive statistics to understand the dataset.\n",
    "Plot label distributions and pixel intensity histograms.\n",
    "Visualize class imbalances to determine the need for class weights.\n",
    "Explore correlations (if applicable).\n",
    "Check image augmentation and ensure consistency in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Swish activation function\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Define the model with Swish activation\n",
    "class SwishResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SwishResNet, self).__init__()\n",
    "        # Load pre-trained ResNet model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        # Replace ReLU with Swish in the model\n",
    "        self.resnet.relu = Swish()\n",
    "        # Modify the final layer to match the number of classes\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SwishResNet()\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: , Best LR = 0.000231, Best WD = 0.000541\n",
      "Epoch 1/2, Loss: 5.8144, Accuracy: 99.33%\n",
      "Epoch 2/2, Loss: 1.8728, Accuracy: 99.17%\n",
      "Test Accuracy: 99.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define Swish activation function\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Define a CNN model with Swish activation\n",
    "class SwishResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SwishResNet, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.relu = Swish()  # Replace ReLU with Swish\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Custom Dataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.data = df.groupby(\"Label\").head(10).reset_index(drop=True)  # 10 images per label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        label_mapping = {\"AD\":0, \"CI\":1, \"CN\":2}  # Adjust if needed\n",
    "        label = label_mapping[self.data.iloc[idx, 2]]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "csv_file = \"Processed_adni_Dataset/adni_dataset_info.csv\"\n",
    "dataset = ImageDataset(csv_file, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Mayfly Algorithm for hyperparameter tuning\n",
    "def mayfly_optimization(num_mayflies=5, generations=1):\n",
    "    best_lr, best_wd = 0.0001, 0.0005  # Default values\n",
    "    best_acc = 0.0\n",
    "\n",
    "    mayflies = [(random.uniform(1e-5, 1e-3), random.uniform(1e-6, 1e-3)) for _ in range(num_mayflies)]\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        for i, (lr, wd) in enumerate(mayflies):\n",
    "            model = SwishResNet(num_classes=4).to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            model.train()\n",
    "            correct, total = 0, 0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            acc = 100 * correct / total\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_lr, best_wd = lr, wd\n",
    "            \n",
    "            # Ensure learning rate and weight decay are positive and adaptive\n",
    "            mayflies[i] = (\n",
    "                max(1e-5, best_lr * (1 + random.uniform(-0.1, 0.1))),  # Adjust LR in small steps\n",
    "                max(1e-6, best_wd * (1 + random.uniform(-0.1, 0.1)))   # Adjust WD adaptively\n",
    "            )\n",
    "        \n",
    "        print(f\"Generation {gen+1}: , Best LR = {best_lr:.6f}, Best WD = {best_wd:.6f}\")\n",
    "    \n",
    "    return best_lr, best_wd\n",
    "\n",
    "# Find best hyperparameters\n",
    "best_lr, best_wd = mayfly_optimization()\n",
    "\n",
    "# Train final model with optimized hyperparameters\n",
    "model = SwishResNet(num_classes=4).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr, weight_decay=best_wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=15):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100-correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 -correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Train and test with optimized parameters\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=2)\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1MYgd-0j7WH"
   },
   "source": [
    "****"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
