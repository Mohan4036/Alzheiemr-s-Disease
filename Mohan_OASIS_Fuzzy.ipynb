{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gx5wldLi5oJ",
    "outputId": "d34eea43-63b3-4b08-d090-7903108a4970"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyswarms in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (1.11.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (3.7.5)\n",
      "Requirement already satisfied: attrs in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (24.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (4.66.5)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyswarms) (6.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=1.3.1->pyswarms) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=1.3.1->pyswarms) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=1.3.1->pyswarms) (2.9.0.post0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->pyswarms) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=1.3.1->pyswarms) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-fuzzy in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn->imblearn) (3.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyswarms\n",
    "!pip install scikit-fuzzy\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a99aCVAF2TMh",
    "outputId": "2d6cf782-caa1-4c37-dbfa-dcba3b49b560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mild Dementia': 0, 'Moderate Dementia': 1, 'Non Demented': 2, 'Very mild Dementia': 3}\n",
      "Batch size: torch.Size([32, 3, 224, 224]), Labels: tensor([2, 0, 1, 3, 3, 0, 3, 3, 0, 2, 0, 3, 0, 0, 0, 0, 3, 0, 0, 3, 3, 1, 3, 3,\n",
      "        2, 2, 0, 1, 2, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize images\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = \"input\"\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "\n",
    "# Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Check class mapping\n",
    "print(dataset.class_to_idx)  # {'1': 0, '2': 1, '3': 2, '4': 3}\n",
    "\n",
    "# Example: Load a batch\n",
    "for images, labels in dataloader:\n",
    "    print(f\"Batch size: {images.shape}, Labels: {labels}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RxeFeMso1mv1",
    "outputId": "1941a00d-e042-475e-8d25-405f05d59894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset Preprocessing & Splitting Completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Set paths\n",
    "dataset_path = \"input\"  # Change this to your dataset path\n",
    "output_dir = \"Processed_output_Dataset\"  # Output directory\n",
    "\n",
    "# Define train-test split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Target image size\n",
    "img_size = (224, 224)\n",
    "\n",
    "# Create train & test directories\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "\n",
    "for folder in [\"Mild Dementia\", \"Moderate Dementia\",\"Non Demented\",\"Very mild Dementia\"]:  # Loop through severity levels\n",
    "    os.makedirs(os.path.join(train_dir, folder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, folder), exist_ok=True)\n",
    "\n",
    "# Function to preprocess and save images\n",
    "def process_and_split_images():\n",
    "    for category in [\"Mild Dementia\", \"Moderate Dementia\",\"Non Demented\",\"Very mild Dementia\"]:  # Iterate through class folders\n",
    "        class_path = os.path.join(dataset_path, category)\n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)  # Shuffle for randomness\n",
    "\n",
    "        split_index = int(len(images) * train_ratio)\n",
    "        train_images, test_images = images[:split_index], images[split_index:]\n",
    "\n",
    "        for image_name in train_images:\n",
    "            process_and_save(image_name, class_path, os.path.join(train_dir, category))\n",
    "\n",
    "        for image_name in test_images:\n",
    "            process_and_save(image_name, class_path, os.path.join(test_dir, category))\n",
    "\n",
    "# Function to load, preprocess, and save images\n",
    "def process_and_save(image_name, src_folder, dest_folder):\n",
    "    src_path = os.path.join(src_folder, image_name)\n",
    "    dest_path = os.path.join(dest_folder, image_name)\n",
    "\n",
    "    try:\n",
    "        with Image.open(src_path) as img:\n",
    "            img = img.convert(\"RGB\")  # Convert to RGB (if grayscale)\n",
    "            img = img.resize(img_size)  # Resize image\n",
    "            img.save(dest_path)  # Save processed image\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {src_path}: {e}\")\n",
    "\n",
    "# Run preprocessing\n",
    "process_and_split_images()\n",
    "print(\" Dataset Preprocessing & Splitting Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at Processed_output_Dataset\\oasis_dataset_info.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Define CSV file path\n",
    "csv_file = os.path.join(output_dir, \"oasis_dataset_info.csv\")\n",
    "\n",
    "# Collect image data\n",
    "image_data = []\n",
    "labels = []\n",
    "for split in [\"train\", \"test\"]: \n",
    "    split_dir = os.path.join(\"input\", split)\n",
    "    split_dir = os.path.join(output_dir, split)\n",
    "    for category in [\"Mild Dementia\", \"Moderate Dementia\",\"Non Demented\",\"Very mild Dementia\"]:\n",
    "        category_dir = os.path.join(split_dir, category)\n",
    "        for image_name in os.listdir(category_dir):\n",
    "            image_path = os.path.join(category_dir, image_name)\n",
    "            image_data.append([image_path, image_name, category])\n",
    "            labels.append(category)\n",
    "\n",
    "# Write to CSV file\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Image_Path\", \"Image_Name\", \"Label\"])\n",
    "    writer.writerows(image_data)\n",
    "\n",
    "print(f\"CSV file saved at {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Processed_output_Dataset/oasis_dataset_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_BXXowo2FkD",
    "outputId": "e2dc9070-ee04-486a-f890-e4b80fcb7c1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Image_Path  \\\n",
      "0  Processed_output_Dataset\\train\\Mild Dementia\\O...   \n",
      "1  Processed_output_Dataset\\train\\Mild Dementia\\O...   \n",
      "2  Processed_output_Dataset\\train\\Mild Dementia\\O...   \n",
      "3  Processed_output_Dataset\\train\\Mild Dementia\\O...   \n",
      "4  Processed_output_Dataset\\train\\Mild Dementia\\O...   \n",
      "\n",
      "                    Image_Name          Label  \n",
      "0  OAS1_0028_MR1_mpr-1_100.jpg  Mild Dementia  \n",
      "1  OAS1_0028_MR1_mpr-1_101.jpg  Mild Dementia  \n",
      "2  OAS1_0028_MR1_mpr-1_102.jpg  Mild Dementia  \n",
      "3  OAS1_0028_MR1_mpr-1_103.jpg  Mild Dementia  \n",
      "4  OAS1_0028_MR1_mpr-1_104.jpg  Mild Dementia  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9488 entries, 0 to 9487\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Image_Path  9488 non-null   object\n",
      " 1   Image_Name  9488 non-null   object\n",
      " 2   Label       9488 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 222.5+ KB\n",
      "None\n",
      "Label\n",
      "Mild Dementia         3000\n",
      "Non Demented          3000\n",
      "Very mild Dementia    3000\n",
      "Moderate Dementia      488\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# View the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check basic information\n",
    "print(df.info())\n",
    "\n",
    "# Check the label distribution\n",
    "print(df['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zhvkYN0m6R5S",
    "outputId": "5ca06df8-651b-4d2d-a7f0-84b8c2da581c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {'Mild Dementia': 0.7906666666666666, 'Moderate Dementia': 4.860655737704918, 'Non Demented': 0.7906666666666666, 'Very mild Dementia': 0.7906666666666666}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Calculate class weights\n",
    "label_counts = Counter(labels)\n",
    "total_samples = sum(label_counts.values())\n",
    "class_weights = {label: total_samples / (len(label_counts) * count) for label, count in label_counts.items()}\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUj2-NHi6nJD"
   },
   "source": [
    "Summary of Steps\n",
    "Use descriptive statistics to understand the dataset.\n",
    "Plot label distributions and pixel intensity histograms.\n",
    "Visualize class imbalances to determine the need for class weights.\n",
    "Explore correlations (if applicable).\n",
    "Check image augmentation and ensure consistency in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# Swish activation function\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Define the model with Swish activation\n",
    "class SwishResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SwishResNet, self).__init__()\n",
    "        # Load pre-trained ResNet model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        # Replace ReLU with Swish in the model\n",
    "        self.resnet.relu = Swish()\n",
    "        # Modify the final layer to match the number of classes\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SwishResNet()\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: , Best LR = 0.000639, Best WD = 0.000305\n",
      "Epoch 1/2, Loss: 10.6865, Accuracy: 99.56%\n",
      "Epoch 2/2, Loss: 8.9619, Accuracy: 99.41%\n",
      "Test Accuracy: 99.88%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define Swish activation function\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Define a CNN model with Swish activation\n",
    "class SwishResNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(SwishResNet, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.relu = Swish()  # Replace ReLU with Swish\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Custom Dataset Class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.data = df.groupby(\"Label\").head(10).reset_index(drop=True)\n",
    "\n",
    "        # Encode string labels to numeric\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data[\"EncodedLabel\"] = self.label_encoder.fit_transform(self.data[\"Label\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx, 0]\n",
    "        label = torch.tensor(self.data.iloc[idx][\"EncodedLabel\"], dtype=torch.long)  # <-- FIXED\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "csv_file = \"Processed_output_Dataset/oasis_dataset_info.csv\"\n",
    "dataset = ImageDataset(csv_file, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Mayfly Algorithm for hyperparameter tuning\n",
    "def mayfly_optimization(num_mayflies=5, generations=1):\n",
    "    best_lr, best_wd = 0.0001, 0.0005  # Default values\n",
    "    best_acc = 0.0\n",
    "\n",
    "    mayflies = [(random.uniform(1e-5, 1e-3), random.uniform(1e-6, 1e-3)) for _ in range(num_mayflies)]\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        for i, (lr, wd) in enumerate(mayflies):\n",
    "            model = SwishResNet(num_classes=4).to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            model.train()\n",
    "            correct, total = 0, 0\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            acc = 100 * correct / total\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_lr, best_wd = lr, wd\n",
    "            \n",
    "            # Ensure learning rate and weight decay are positive and adaptive\n",
    "            mayflies[i] = (\n",
    "                max(1e-5, best_lr * (1 + random.uniform(-0.1, 0.1))),  # Adjust LR in small steps\n",
    "                max(1e-6, best_wd * (1 + random.uniform(-0.1, 0.1)))   # Adjust WD adaptively\n",
    "            )\n",
    "        \n",
    "        print(f\"Generation {gen+1}: , Best LR = {best_lr:.6f}, Best WD = {best_wd:.6f}\")\n",
    "    \n",
    "    return best_lr, best_wd\n",
    "\n",
    "# Find best hyperparameters\n",
    "best_lr, best_wd = mayfly_optimization()\n",
    "\n",
    "# Train final model with optimized hyperparameters\n",
    "model = SwishResNet(num_classes=4).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_lr, weight_decay=best_wd)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=15):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100-correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 -correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Train and test with optimized parameters\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=2)\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1MYgd-0j7WH"
   },
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CfY5ZPVS7RIy",
    "outputId": "4e95ba24-f19c-4752-8de3-5d0035ed0a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 9.0801, Accuracy: 99.47%\n",
      "Epoch 2/20, Loss: 5.5937, Accuracy: 99.25%\n",
      "Epoch 3/20, Loss: 6.1902, Accuracy: 99.25%\n",
      "Epoch 4/20, Loss: 5.5805, Accuracy: 99.34%\n",
      "Epoch 5/20, Loss: 3.1035, Accuracy: 99.09%\n",
      "Epoch 6/20, Loss: 2.8946, Accuracy: 99.12%\n",
      "Epoch 7/20, Loss: 2.7700, Accuracy: 99.06%\n",
      "Epoch 8/20, Loss: 1.5184, Accuracy: 99.03%\n",
      "Epoch 9/20, Loss: 4.3754, Accuracy: 99.12%\n",
      "Epoch 10/20, Loss: 1.9333, Accuracy: 99.06%\n",
      "Epoch 11/20, Loss: 0.8503, Accuracy: 99.03%\n",
      "Epoch 12/20, Loss: 1.5541, Accuracy: 99.09%\n",
      "Epoch 13/20, Loss: 2.2333, Accuracy: 99.03%\n",
      "Epoch 14/20, Loss: 1.1694, Accuracy: 99.06%\n",
      "Epoch 15/20, Loss: 0.7322, Accuracy: 99.03%\n",
      "Epoch 16/20, Loss: 5.4318, Accuracy: 99.22%\n",
      "Epoch 17/20, Loss: 2.8081, Accuracy: 99.12%\n",
      "Epoch 18/20, Loss: 5.2534, Accuracy: 99.16%\n",
      "Epoch 19/20, Loss: 4.2895, Accuracy: 99.16%\n",
      "Epoch 20/20, Loss: 1.5259, Accuracy: 99.03%\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         2\n",
      "   Uncertain       0.00      1.00      0.00         0\n",
      "\n",
      "    accuracy                           0.88         8\n",
      "   macro avg       0.75      0.88      0.67         8\n",
      "weighted avg       1.00      0.88      0.92         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# **Fuzzy Decision-Based Classification**\n",
    "def fuzzy_decision(output_probs, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Apply fuzzy logic to classify an image.\n",
    "    If the highest probability is below a threshold, classify as 'uncertain'.\n",
    "    \"\"\"\n",
    "    max_prob, pred_class = torch.max(output_probs, dim=1)  # Get highest probability and class index\n",
    "    pred_class[max_prob < threshold] = -1  # If probability is low, mark as 'uncertain'\n",
    "    return pred_class.cpu().numpy()\n",
    "\n",
    "# Testing function with fuzzy decision logic\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)  # Convert to probabilities\n",
    "            preds = fuzzy_decision(probs)  # Apply fuzzy decision logic\n",
    "\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds)\n",
    "\n",
    "    return true_labels, predicted_labels\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=20)\n",
    "\n",
    "# Evaluate the model\n",
    "y_true, y_pred = test_model(model, test_loader)\n",
    "\n",
    "# Convert -1 to \"Uncertain\" class\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred_labels = np.where(y_pred == -1, \"Uncertain\", y_pred)\n",
    "# Convert all true and predicted labels to strings\n",
    "y_true_str = [str(label) for label in y_true]\n",
    "y_pred_str = [str(label) for label in y_pred_labels]\n",
    "\n",
    "# Now, generate the classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_true_str, y_pred_str, zero_division=1))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
